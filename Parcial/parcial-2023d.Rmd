---
title: "Parcial-2023"
subtitle: "Thomas Rudolf / Ximena Paz"
output: html_document
---

**Entrega:** 10 de octubre antes de las 16:00 horas, por correo electrónico con 
el título fundamentos-parcial, un solo documento (pdf/html) por equipo.

**Instrucciones:**

* Tus respuestas deben ser claras y debes explicar 
los resultados, incluye también tus procedimientos/código de manera ordenada, 
y el código comentado.

* Se evaluará la presentación de resultados (calidad de las gráficas, tablas, 
...), revisa la sección de visualización en las notas.

* Se puede realizar individual o en parejas.

* Si tienes preguntas puedes escribirlas en el anuncio de canvas del examen.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, error=TRUE, message = FALSE)

#Se cargan las librerías necesarias 
library(tidyverse)
library(readr)
library(patchwork)
library(purrr)
library(nullabor)
```

## Pruebas de hipótesis

Nos solicitan hacer un análisis con el objetivo de probar un material nuevo para suela de zapatos (el material B) y ver si es comparable con el material que se usa normalmente (el material A).

Nos dan el siguiente conjunto de datos:

```{r}
zapatos <- read_csv("datos/zapatos-1.csv")
zapatos
```

1. Realiza una prueba de hipótesis visual y describe tus conclusiones (cuál es el
nivel de significancia de la prueba?).

```{r}

#Se analizaran la base de datos de zapatos.
glimpse(zapatos)
g_isnorm <- ggplot(zapatos, aes(sample= desgaste)) +
  geom_qq(distribution = stats::qnorm) +
  geom_qq_line(color = "red") +
 facet_wrap(zapatos$material)
g_isnorm
g_box <-  ggplot(zapatos, aes(y= desgaste, x = material)) +
  geom_boxplot()+
  geom_jitter(alpha = 1/3) +
  facet_wrap(zapatos$material)
g_isnorm + g_box

```
Tenemos dos columnas que nos están dando el material con el que se esta trabajando así como el desgaste en cada una de nuestras entradas 

```{r}
# Utilizamos lineup para realizar nuestra prueba de hipótesis visual. Donde buscamos entontrar alguna diferencia para así encontrar evidencia en contra de la hipótesis nula

set.seed(123)
reps <- lineup(null_permute("material"), zapatos, n = 20)
reps

reps_mixed <- reps %>% 
  mutate(group_01 = factor(digest::digest2int("material") %% 177))
graph_quantile <- ggplot(reps_mixed, aes(y= desgaste, x = material)) +
  geom_boxplot() +
  geom_jitter(alpha = 1/3) +
  #geom_point()+
  #geom_tufteboxplot() +
  facet_wrap(reps_mixed$.sample)
graph_quantile
#decrypt("nsW7 Ykjk l3 gCPljlC3 Km") --> grafica 18
```

Observamos que nuestras 20 gráficas son muy parecidas por lo que no encontramos evidencia suficiente para rechazar la hipótesis nula y decir que los materiales son distintos entre si.

2. Realiza una prueba de permutaciones para la diferencia de las medias, escribe la hipótesis nula, la hipótesis alterna y tus conclusiones.

H0: El material B es igual con el material A

Ha: El material B no es igual con el material A

```{r}
set.seed(123)
#Se filtraran los los materiales 1 y 2 para poder comparar ambos desgastes
materialA  <- zapatos %>% filter(material == 1)
materialB  <- zapatos %>% filter(material == 2)
material_tbl <- tibble(wear_materialA = materialA$desgaste, 
                       wear_materialB = materialB$desgaste)
diff_material <- material_tbl %>%  
  summarise(mean_wear_mat1 = mean(wear_materialA), 
            mean_wear_mat2 = mean(wear_materialB),
            diff_mat = mean_wear_mat2 - mean_wear_mat1)
 diff_material
 

# permutación
valores_ref <- lineup(null_permute("material"), zapatos, n = 10000) %>% 
  mutate(materia_as_chr = as.character(material)) %>% 
  group_by(.sample, material) %>% 
  summarise(wear = mean(desgaste)) %>% 
  pivot_wider(names_from = material, values_from = wear) %>%
  mutate(diff = `1` - `2`)
# decrypt("nsW7 Ykjk l3 gCPljlC3 44Tb")
g_valor_ref_q <- ggplot(valores_ref, aes(sample = diff)) +
  geom_qq(distribution = stats::qunif) +
  geom_hline(yintercept = diff_material$diff_mat, color = "red") 
g_valor_hist <- ggplot(valores_ref, aes(x = diff)) +
  geom_histogram(binwidth = 0.4) +
  coord_flip() +
  geom_vline(xintercept = diff_material$diff_mat, color = "red")
g_valor_ref_q + g_valor_hist


disp_perm <- ecdf(valores_ref$diff)
2 * min(disp_perm(diff_material$diff_mat), (1-disp_perm(diff_material$diff_mat)))
```
**Explicación**:

De acuerdo a la diferencia de medias, obtenemos un valor p de 0.7082 que es nuestro nivel de significancia de la prueba, lo que nos lleva a no rechazar la hipótesis nula por lo que decimos que no hay evidencia suficiente que indique que el desgaste entre el material A y B son distintos.

En nuestras gráficas también podemos observar que la media en ambos casis es muy similar por lo que no encontramos diferencia significativa entre el material A y B 


3. Después de discutir con los responsables del proyecto descubrimos que nos 
faltaba conocer detalles del proceso generador de datos: el experimento se realizó asignando al azar un material a uno de sus zapatos y el otro material al otro zapato de cada niño.
¿Cómo incorporas esta información en tu prueba de hipótesis del inciso 2? ¿Cambian
tus conclusiones?

```{r}
zapatos2 <- read_csv("datos/zapatos-2.csv")
zapatos2
```

**Explicacicón**:

De acuerdo a este nuevo valor podemos indicar que la diferencia que tenemos se basa en los niños y no en el tipo de material que tenemos. Por lo que contamos con una muestras pareada que el valor del zapato A y B son dependientes. El valor de p = 0.8571429.

```{r}
zapatos_tbl <- zapatos2 %>% group_by(niño) %>% 
  pivot_wider(names_from = niño, values_from = desgaste) 

zapatos_tbl %>% 
  bind_rows(diff = zapatos_tbl[1,] - zapatos_tbl[2,])
#diff_material_per_child <- zapatos_tbl[3,2:11]
# se tomo los valores de la diferencia de desgaste de por niños via "copy and paste" para hacer el nuevo data frame y analizarlo (dmpc = difference of material per child).
dmpc_tbl <- tibble(dmpc = c(-0.800, -0.600, -0.300,  0.100, -1.10, 0.200, -0.300,  -0.5,  -0.5, -0.300))
diff_mean <- mean(dmpc_tbl$dmpc)

calc_diferencia_2 <- function(data){
  data %>% 
    group_by(dmpc) %>% 
    summarise(wear = mean(dmpc), .group = 'drop') %>% 
    pull(wear)
}
mean_org <- mean(calc_diferencia_2(dmpc_tbl))
set.seed(123)
reps <- lineup(null_permute("dmpc"), dmpc_tbl, n = 10000)
# decrypt("nsW7 Ykjk l3 gCPljlC3 FFbb")
valores_ref2 <- reps %>% 
  group_by(.sample) %>% 
  nest() %>% 
  mutate(diff = lapply(data, calc_diferencia_2)) %>% 
  unnest(diff)

valores_ref2

g_valor_ref2_q <- ggplot(valores_ref2, aes(sample = diff)) +
  geom_qq(distribution = stats::qnorm) +
  geom_hline(yintercept = mean_org, color = "red") 
 

g_valor_ref2_hist <- ggplot(valores_ref2, aes(y = diff)) +
  geom_histogram() +
  geom_hline(yintercept = mean_org, color = "red") 
g_valor_ref2_q +  g_valor_ref2_hist


disp_perm <- ecdf(valores_ref2$diff)
2 * min(disp_perm(diff_mean), (1-disp_perm(diff_mean)))
```



## Bootstrap

#### Antecedentes 

En México, las elecciones tienen lugar un domingo, los resultados oficiales 
del proceso se presentan a la población una semana después. A fin de evitar 
proclamaciones de victoria injustificadas durante ese periodo el INE organiza un 
conteo rápido. Un conteo rápido es un procedimiento para estimar, a partir de una muestra 
aleatoria de casillas, el porcentaje de votos a favor de cada opción en la boleta. 

En 2021 se realizó un conteo rápido para estimar los resultados de la [consulta popular 2021](https://ine.mx/conteo-rapido-consulta-popular-2021/) y en los siguientes
incisos estimarán los resultados de la consulta y evaluarán la metodología. 

##### Diseño de la muestra

El diseño utilizado en los conteos rápidos es *muestreo estratificado simple*, 
es decir:

i) se particionan las casillas de la pablación en estratos (cada casilla
pertenece a exactamente un estrato), y 

ii) dentro de cada estrato se usa *muestreo aleatorio* para seleccionar las 
casillas que estarán en la muestra. 

##### Estimación 

Una de las metodolgías de estimación, que se usa en el conteo rápido (tanto de 
elecciones como en consultas) es *estimador de razón combinado*, con
intervalos de 95% de confianza construidos con el método normal y error 
estándar bootstrap. En este ejercicio debes construir intervalos usando este 
procedimiento.

Para cada opción en la consulta (sí/no/nulos) usarás la muestra del conteo rápido
para estimar los resultados de la consulta.

1. Calcula el estimador de razón combinado, para muestreo estratificado la 
fórmula es:

$$\hat{p}=\frac{\sum_h \frac{N_h}{n_h} \sum_i Y_{hi}}{\sum_h \frac{N_h}{n_h} \sum_i X_{hi}}$$
  donde:

  * $\hat{p}$ es la estimación de la proporción de votos que recibió la opción (ej: *sí*).

  * $Y_{hi}$ es el número total de votos que recibió *la opción* (ej: *sí*)
en la $i$-ésima casillas, que pertence al $h$-ésimo estrato.

  * $X_{hi}$ es el número total de votos en la $i$-ésima casilla, que pertence al 
$h$-ésimo estrato. 

  * $N_h$ es el número total de casillas en el $h$-ésimo estrato.

  * $n_h$ es el número de casillas del $h$-ésimo estrato que se seleccionaron en 
la muestra.


##### Datos 

Necesitarás los siguientes datos:

* Cómputos [aquí](https://computos.cp2021.ine.mx/votos-distrito/mapa)

* Muestra del conteo rápido usada en la estimación [aquí](https://ine.mx/conteo-rapido-consulta-popular-2021/)

```{r}
# preprocesamiento de tablas de datos
computos <- read_delim("datos/20210802-2130_INE-CONSULTA-POPULAR-2021/20210802-2130_COMPUTOS-INE-CP2021.csv", 
    delim = "|", escape_double = FALSE, trim_ws = TRUE, quote = "\'",
    skip = 5)
computos <- computos |> 
  rename(ID = CLAVE_MRCP) |> 
  mutate(ESTRATO = str_c(str_pad(ID_ENTIDAD, 2, pad = "0"), 
                         str_pad(ID_DISTRITO_FEDERAL, 2, pad = "0")),
         LISTA_NOMINAL = LISTA_NOMINAL_MRCP, 
         TOTAL = TOTAL_OPINIONES)

muestra <- read_delim("https://ine.mx/wp-content/uploads/2021/08/Conteos-ConsPop21-Lista-MuestraCalculo.txt", delim = "|", skip = 1) 
muestra_tidy <- muestra |> 
  mutate(
    ID_ESTADO = str_pad(ID_ESTADO, 2, pad = "0"),
    SECCION = str_pad(SECCION, 4, pad = "0"),
    ID_CASILLA = str_pad(ID_CASILLA, 2, pad = "0"),
    ID = str_c(ID_ESTADO, SECCION, TIPO_CASILLA, ID_CASILLA)
    ) |> 
  group_by(ESTRATO) |> 
  mutate(n = n()) |> 
  ungroup()
```
Se realizará el cálculo de los distintos componentes del estimador para los tres tipos de respuesta que tenemos: si, no y nulos

```{r}

#Estimador si 

#Se filtraran los elementos necesarios de acuerdo a cada una de las variables de nuestro estimador

estim_p__gorro_si <- function(sample2Eval, pop_total){
  y_hi_si <- sample2Eval %>%
    group_by(ESTRATO) %>%
    summarise(count_yes = sum(sample2Eval$SI)) 

  x_hi <- sample2Eval %>%
    ungroup() %>%
    group_by(ID_CASILLA, ESTRATO) %>%
    summarise(count_votos = sum(TOTAL), .groups = 'drop')

  N_h <- pop_total %>%
    group_by(ESTRATO) %>%
    summarise(count_casilla = n_distinct(pop_total$ID_MRCP))

  n_h <- muestra_tidy %>%
    group_by(ESTRATO) %>%
    summarise(count_casilla = n_distinct(muestra_tidy$ID_CASILLA))

  proportion <- inner_join(N_h, n_h, by = "ESTRATO") %>%
    mutate(division = count_casilla.x / count_casilla.y)

  a_si <- inner_join(proportion, y_hi_si, by = "ESTRATO") %>%
    mutate(mult = division * count_yes)

    b <- inner_join(proportion, x_hi, by="ESTRATO") %>%
      mutate(mult = division * count_votos)

  p_gorro_si <- sum(a_si$mult) / sum(b$mult)

}

p_gorro_si <- estim_p__gorro_si(muestra_tidy, computos)
  
```

```{r}
#Estimador no
estim_p__gorro_no <- function(sample2Eval, pop_total){
  y_hi_no <- sample2Eval %>%
    group_by(ESTRATO) %>%
    summarise(count_no = sum(sample2Eval$NO)) 

  x_hi <- sample2Eval %>%
    ungroup() %>%
    group_by(ID_CASILLA, ESTRATO) %>%
    summarise(count_votos = sum(TOTAL), .groups = 'drop')

  N_h <- pop_total %>%
    group_by(ESTRATO) %>%
    summarise(count_casilla = n_distinct(pop_total$ID_MRCP))

  n_h <- sample2Eval %>%
    group_by(ESTRATO) %>%
    summarise(count_casilla = n_distinct(sample2Eval$ID_CASILLA))

  proportion <- inner_join(N_h, n_h, by = "ESTRATO") %>%
    mutate(division = count_casilla.x / count_casilla.y)

  a_no <- inner_join(proportion, y_hi_no, by = "ESTRATO") %>%
    mutate(mult = division * count_no)
  
  b <- inner_join(proportion, x_hi, by="ESTRATO") %>%
    mutate(mult = division * count_votos)

  p_gorro_no <- sum(a_no$mult) / sum(b$mult)
}
p_gorro_no <- estim_p__gorro_no(muestra_tidy, computos)

```

```{r}

#Estimador nulos
estim_p__gorro_nulos<- function(sample2Eval, pop_total){
  
  y_hi_nulos <- sample2Eval %>%
    group_by(ESTRATO) %>%
    summarise(count_nulos = sum(sample2Eval$NULOS)) 

  x_hi <- sample2Eval %>%
    ungroup() %>%
    group_by(ID_CASILLA, ESTRATO) %>%
    summarise(count_votos = sum(TOTAL), .groups = 'drop')

  N_h <- pop_total %>%
    group_by(ESTRATO) %>%
    summarise(count_casilla = n_distinct(pop_total$ID_MRCP))

  n_h <- sample2Eval %>%
    group_by(ESTRATO) %>%
    summarise(count_casilla = n_distinct(sample2Eval$ID_CASILLA))


  proportion <- inner_join(N_h, n_h, by = "ESTRATO") %>%
    mutate(division = count_casilla.x / count_casilla.y)

  a_nulos <- inner_join(proportion, y_hi_nulos, by = "ESTRATO") %>%
    mutate(mult = division * count_nulos)

  b <- inner_join(proportion, x_hi, by="ESTRATO") %>%
    mutate(mult = division * count_votos)

  p_gorro_nulos <- sum(a_nulos$mult) / sum(b$mult)
}
 p_gorro_nulos <-estim_p__gorro_nulos(muestra_tidy, computos)
```

```{r}

#Se calcularan las proporciones de cada estimador

total <- p_gorro_no + p_gorro_nulos + p_gorro_si

percentage_p_si <- p_gorro_si / total
percentage_p_no <- p_gorro_no / total
percentage_p_nulos <- p_gorro_nulos / total

percentage_p_si
percentage_p_no
percentage_p_nulos

```
**Explicación**
Calculando las proporciones de nuestros estimadores tenemos que el 93.1% corresponde a votos si, 1.5% a votos que no y 5.4% corresponde a votos nulos. 


2. Utiliza **bootstrap** para calcular el error estándar, y reporta tu 
estimación del error.
    + Genera 1000 muestras bootstrap.
    + Recuerda que las muestras bootstrap tienen que tomar en cuenta la 
    metodología que se utilizó en la selección de la muestra original, en este
    caso implica que para cada remuestra debes tomar muestra aleatoria independiente
    dentro de cada estrato.
```{r}

#Creamos una función con el peso de cada uno de los estimadores para poder realizar nuestra muestra con los pesos de la muestra original
set.seed(1234)
esti_all <- function(sample2Eval, pop_total){
  p_gorro_si <-estim_p__gorro_si(sample2Eval,  pop_total)
  p_gorro_no <-estim_p__gorro_no(sample2Eval,  pop_total)
  p_gorro_nulos <-estim_p__gorro_nulos(sample2Eval,  pop_total)

 
  total <- p_gorro_no + p_gorro_nulos + p_gorro_si

  percentage_p_si <- p_gorro_si / total
  percentage_p_no <- p_gorro_no / total
  percentage_p_nulos <- p_gorro_nulos / total
  perc_total <- c(percentage_p_si, percentage_p_no, percentage_p_nulos)
}
  
get_sample <- function(sample2eval){
  resample <- slice_sample(sample2eval %>% group_by(ESTRATO), prop = 1, replace = TRUE)
}
# Calculando 1000 bootstraps: para ahorrar tiempo de, se guardo el resultado de bootstrap en una variable .rds y se lee solamente para el siguente analisis.
# boot_sample <- map(1:1000,~ esti_all(get_sample(muestra_tidy), computos))
# write_rds(boot_sample, "cache/boot_sample.rds")
boot_sample <- read_rds("cache/boot_sample.rds")
# resultado: separar los valores en arrarys para aplicar sd()
# inicial:
p_hat_si_vec <- c(boot_sample[[1]][1])  
p_hat_no_vec <- c(boot_sample[[1]][2])  
p_hat_nu_vec <- c(boot_sample[[1]][3])  
# adjuntar los demas valors
for(idx in 2:1000){
  p_hat_si_vec <- c(p_hat_si_vec, boot_sample[[idx]][1])  
  p_hat_no_vec <- c(p_hat_no_vec, boot_sample[[idx]][2])  
  p_hat_nu_vec <- c(p_hat_nu_vec, boot_sample[[idx]][3])  
}

# data frame p_hat
p_hat_tbl <- tibble(p_hat_si = p_hat_si_vec, 
                p_hat_no = p_hat_no_vec,
                p_hat_nu = p_hat_nu_vec)

# calular el error estandard
ee_p_hat_si <- sd(p_hat_si_vec)
ee_p_hat_no <- sd(p_hat_no_vec)
ee_p_hat_nu <- sd(p_hat_nu_vec)
ee_res_boot <- tibble(ee_p_hat_si, ee_p_hat_no, ee_p_hat_nu)
ee_res_boot

g_si <- ggplot(p_hat_tbl, aes(p_hat_si)) + 
  geom_histogram() +
  geom_vline(xintercept = mean(p_hat_tbl$p_hat_si), colour = "red")
g_no <- ggplot(p_hat_tbl, aes(p_hat_no)) + 
  geom_histogram() +
  geom_vline(xintercept = mean(p_hat_tbl$p_hat_no), colour = "red")
g_nu <- ggplot(p_hat_tbl, aes(p_hat_nu)) + 
  geom_histogram() +
  geom_vline(xintercept = mean(p_hat_tbl$p_hat_nu), colour = "red")

```

3. Construye un intervalo del 95% de confianza utilizando el método normal. Revisa 
si el supuesto de normalidad es razonable.

```{r}
# intervalos de confianza p_hat_si
interv_p_hat_si_95 <- c(percentage_p_si - 2*ee_p_hat_si, percentage_p_si + 2*ee_p_hat_si)
interv_p_hat_si_95
#el supuesto de normalidad es razonable?
g_si_qq <- ggplot(p_hat_tbl, aes(sample = p_hat_si)) +
  geom_qq(distribution  = stats::qnorm) +
  geom_qq_line(color = "red") +
  geom_hline(yintercept = interv_p_hat_si_95[1], colour="green")+
  geom_hline(yintercept = interv_p_hat_si_95[2], colour="green")
g_si + g_si_qq
# intervalos de confianza p_hat_no
interv_p_hat_no_95 <- c(percentage_p_no - 2*ee_p_hat_no, percentage_p_no + 2*ee_p_hat_no)
interv_p_hat_no_95
#el supuesto de normalidad es razonable?
g_no_qq <- ggplot(p_hat_tbl, aes(sample = p_hat_no)) +
  geom_qq(distribution  = stats::qnorm) +
  geom_qq_line(color = "red") +
  geom_hline(yintercept = interv_p_hat_no_95[1], colour="green")+
  geom_hline(yintercept = interv_p_hat_no_95[2], colour="green")
g_no + g_no_qq

# intervalos de confianza p_hat_nu
interv_p_hat_nu_95 <- c(percentage_p_nulos - 2*ee_p_hat_nu, percentage_p_nulos + 2*ee_p_hat_nu)
interv_p_hat_nu_95 
#el supuesto de normalidad es razonable?
g_nu_qq <- ggplot(p_hat_tbl, aes(sample = p_hat_nu)) +
  geom_qq(distribution  = stats::qnorm) +
  geom_qq_line(color = "red") +
  geom_hline(yintercept = interv_p_hat_nu_95[1], colour="green")+
  geom_hline(yintercept = interv_p_hat_nu_95[2], colour="green")
g_nu + g_nu_qq

```
**Explicación**: Las gráficas para determinar si la distribución Bootstrap de los votos son normales indican que si.

Los intervalos de confianza son:

$intervalos_{votoSI}    = (0.8997795 \  0.9617113)$\n

$intervalos_{votoNO}    = (0.01384254 \  0.01571683)$\n

$intervalos_{votoNULOS} = (0.02306313 \ 0.08588669)$\n

*voto SI:* Lo cola izq. de la distribución SI es un poco más larga que la normal mientras la cola derecha es un poco más corta.

*voto NO:* Lo cola izq. de la distribución NO es un poco más larga (menos de la SI) que la normal mientras la cola derecha es un poco más larga. sin embargo, casi no se nota en el histograma. 

*voto NULOS:* cola izq. de la distribución NULOS es un poco más larga (menos de la SI) que la normal mientras la cola derecha es un poco más corta. sin embargo, casi no se nota en el histograma.

*Resumen:* Observamos que las tres distribuciones pueden ser considerados norma dentro de un intervalo de 95% (líneas verdes)


4. Reporta tus intervalos en una tabla. Compara la longitud de los 3 intervalos y 
describe que observas.

```{r}
#crear una tabla con los intervalos

tabla_intervalos <- tibble(p = c("p_hat_si", "p_hat_no","p_hat_nulos"),
                            low = c(interv_p_hat_si_95[1], interv_p_hat_no_95[1], interv_p_hat_nu_95[1]), 
                            up = c(interv_p_hat_si_95[2], interv_p_hat_no_95[2], interv_p_hat_nu_95[2]), 
                            int_len =c(interv_p_hat_si_95[2] - interv_p_hat_si_95[1],
                                       interv_p_hat_no_95[2] - interv_p_hat_no_95[1],
                                       interv_p_hat_nu_95[2] - interv_p_hat_nu_95[1]) )
tabla_intervalos

```


3. ¿Tus intervalos contienen los valores observados en los cómputos? Explica los
resultados observados.

```{r}
p_si_total <- sum(computos$OPINION_SI)/sum(computos$TOTAL)
print("¿el valor final de SI está dentro del intervalo estimado?")
(p_si_total>interv_p_hat_si_95[1] & p_si_total<interv_p_hat_si_95[2])
p_no_total <- sum(computos$OPINION_NO)/sum(computos$TOTAL)
print("¿el valor final de NO está dentro del intervalo estimado?")
(p_no_total>interv_p_hat_no_95[1] & p_no_total<interv_p_hat_no_95[2])
p_nu_total <- sum(computos$NULOS)/sum(computos$TOTAL)
print("¿el valor final de NULO está dentro del intervalo estimado?")
(p_nu_total>interv_p_hat_nu_95[1] & p_nu_total<interv_p_hat_nu_95[2])
```
**Explicación**

Los valores del total de la población a votar a SI es más grande y no está dentro del intervalo calculado. Los votos NULOS son menos en la población población total que en la muestra. Una razón puede ser la selección de la muestra que probablemente no es representativo.  Otra razón puede ser que las muestras fueran tomadas en los primeros 2 horas y media que cerraron las casillas y todavía no había una tendencia clara.


#### Calibración

Selecciona al menos 50 muestras del mismo tamaño y con el mismo diseño que la 
muestra utilizada en el conteo rápido. Esto es, selecciona el 
mismo número de casillas, usando muestreo aleatorio simple dentro de cada estrato.

* Para cada muestra calcula un intervalo del 95% de confianza usando bootstrap.

```{r}
# este estimador hace lo mismo que estimador_p(), la diferencia es el tio de sample2eval, es la muestra de computos_tidy, se ajustaron algunas variable: ID en lugar de ID_CASILLA, OPINION_NO en lugar de NO y OPINION_SI en lugar de SI
estimador_p_comp <- function(sample2eval, pop_total){
  
  Y_hi <- sample2eval %>% 
    group_by(ESTRATO, ID) %>% 
    summarise(votos_si = sum(OPINION_SI), votos_no = sum(OPINION_NO),votos_nu = sum(NULOS))

  X_hi <- sample2eval %>% 
    group_by(ESTRATO, ID) %>% 
    summarise(votos_TOTAL = sum(TOTAL))

  N <- pop_total %>%  
    group_by(ESTRATO) %>% 
    summarise(N = sum(N))
  n <- sample2eval %>% 
    group_by(ESTRATO) %>% 
    summarise(n = sum(N))

  den_tot <- sum(N$N/n$n *sum(X_hi$votos_TOTAL))
  p_hat_si <- sum(N$N/n$n *sum(Y_hi$votos_si))/(den_tot)
  p_hat_no <- sum(N$N/n$n *sum(Y_hi$votos_no))/(den_tot)
  p_hat_nu <- sum(N$N/n$n *sum(Y_hi$votos_nu))/(den_tot)
  perc_sample <- tibble(p_hat_si, p_hat_no, p_hat_nu, 
                        check = p_hat_si + p_hat_no + p_hat_nu)
}


set.seed(389)
sim_interval <- function(rep, size = 1745, id = "si"){
  muestra_cr <- slice_sample(computos_tidy, n=size)
  total_est_tbl <- estimador_p_comp (muestra_cr, computos_tidy)
  if(id == "si"){
    total_est <- total_est_tbl$p_hat_si
  }
  if(id == "no"){
    total_est <- total_est_tbl$p_hat_no
  }
  if(id == "nu"){
    total_est <- total_est_tbl$p_hat_nu
  }
  # define el estimador
  calc_estimador <- function(data){
    p_hat<-estimador_p_comp(data, computos_tidy)
    if(id == "si"){
      p_hat_out <- p_hat$p_hat_si
    }
    if(id == "no"){
      p_hat_out <- p_hat$p_hat_no
    }
    if(id == "nu"){
      p_hat_out <- p_hat$p_hat_nu
    }
    class(p_hat_out)
    p_hat_out
  }
  # define el proceso de remuestra
  muestra_boot <- function(data){
    slice_sample(data, prop = 1, replace = TRUE)
  }

 totales_boot <-  map_dbl(1:1000, ~ calc_estimador(muestra_boot(muestra_cr))) %>% 
    tibble(total_boot = .) %>% 
    summarise(ee_boot = sd(total_boot)) %>% 
    mutate(inf = total_est - 2*ee_boot, sup = total_est + 2*ee_boot) %>% 
    mutate(rep = rep)
  totales_boot
}

# Se guardaron los resultas de la simualción para el siguiente analisis para no tenerlo que correr neuvamente. Cada simulación duro aprox 2 horas en posit-cloud.

#sim_intervalo_si <- map(1:50, ~sim_interval(.x, size = 1745, id = "si"))
#write_rds(sim_intervalo_si, "cache/sim_intervalo_si.rds")

sim_intervalo_si <- read_rds("cache/sim_intervalo_si.rds")
#sim_intervalo_nu <- map(1:50, ~sim_interval(.x, size = 1745, id = "nu"))
#write_rds(sim_intervalo_nu, "cache/sim_intervalo_nu.rds")
sim_intervalo_no <- read_rds("cache/sim_intervalo_no.rds")
#sim_intervalo_no <- map(1:50, ~sim_interval(.x, size = 1745, id = "no"))
#write_rds(sim_intervalo_no, "cache/sim_intervalo_no.rds")
sim_intervalo_nu <- read_rds("cache/sim_intervalo_nu.rds")

```

**Explicación**
Se ajustó el estimador de los votos a los datos que se encuentra en $computos$ y se trabajo con un df $computos_tidy$. Se tomo 50 muestras de tamaño 1745 de $computos_tidy$ y con dada una de estas muestras se realizó un Bootstrap de 1000. Los resultados se guardó en tres archivos de .rds: uno para SI, uno para NO y uno para NULOS. los resultados son los 50 intervalos de confianza para cada resultado de los votos.

* Grafica los intervalos y calcula la proporción de ellos que contienen el 
verdadero valor observado. Describe tus observaciones y compara con el intervalo 
obtenido en el ejercicio anterior.

```{r}
# graficas para calibaracion SI
P_expected <- p_si_total
sim_intervalo_si_tbl <- sim_intervalo_si |> 
    bind_rows() |>
            mutate(cubre = inf < P_expected & P_expected < sup) 
intervalo_si_plot <-  ggplot(sim_intervalo_si_tbl, aes(x = rep)) +
      geom_hline(yintercept = P_expected, colour = "red") +
      geom_linerange(aes(ymin = inf, ymax = sup, colour = cubre)) +
  labs(title = "calibaración SI") +
  ylab("invervalls")

# graficas para calibaración NO    
P_expected <- p_no_total
sim_intervalo_no_tbl <- sim_intervalo_no |> 
    bind_rows() |>
            mutate(cubre = inf < P_expected & P_expected < sup) 
intervalo_no_plot <-  ggplot(sim_intervalo_no_tbl, aes(x = rep)) +
      geom_hline(yintercept = P_expected, colour = "red") +
      geom_linerange(aes(ymin = inf, ymax = sup, colour = cubre)) +
  labs(title = "calibaración NO") +
  labs(title = "calibaración NO") +
  ylab("invervalls")

 
# graficas para calibaración NULOS   
P_expected <- p_nu_total
sim_intervalo_nu_tbl <- sim_intervalo_nu |> 
    bind_rows() |>
            mutate(cubre = inf < P_expected & P_expected < sup) 
intervalo_nu_plot <-  ggplot(sim_intervalo_nu_tbl, aes(x = rep)) +
  geom_hline(yintercept = P_expected, colour = "red") +
  geom_linerange(aes(ymin = inf, ymax = sup, colour = cubre))+
  labs(title = "calibaración NULOS") +
  ylab("invervalls")


intervalo_si_plot 
intervalo_no_plot 
intervalo_nu_plot

```
**Explicación**

En estos tres graficas se ve los resultados de los intervalos de confianza para para tipo de voto. Para el valor final se tomó la suma de todos los votos a favor, en contra o nulos y se dividió entre el número de votos total. Para en $SI$ y $NULOS$ hay bastante intervalos que no son incluyen el valor verdadero del resultado final (SI-11, NULOS-18):  También se nota que los intervalos de $SI$ estimados/simulados que no cumplen son más arriba del valor final mientras lo intervalos de $NULOS$ que no cumplen son abajo del valor final. Es puede indicar que hay cierta relación entre estos estimaciones "no correctas". Los intervalos para $NO$ parecen bien. Solo hay 4 intervalos que no tienen el valor final. Además hay uno arriba y tres abajo.

#### Análisis Exploratorio

Un voto nulo corresponde a una boleta donde el ciudadano acudió a las urnas
y anuló su voto. 

Antes de contestar los siguiente incisos piensen que rango esperarían ver para la
proporción de votos nulos en una casilla.

* Describe la distribución de datos nulos en la muestra, y como se relaciona con 
el total de votos, realiza gráficas y describe tus observaciones.

* En la distribución de proporción de nulos se observan datos atípicos, ¿cuál 
crees que sea la razón de estas observaciones extremas? ¿consideras que se
deben eliminar de la muestra antes de realizar la estimación?

```{r}
votos_total <- sum(computos$TOTAL_OPINIONES)
votos_nulos_total <- sum(computos$NULOS)
votos_total_muestra <- sum(muestra$TOTAL)
votos_nulos_muestra <- sum(muestra$NULOS)

(perc_nulos_total <- votos_nulos_total/votos_total)
#perc_nulos_total
(perc_nulos_muestra <- votos_nulos_muestra/votos_total_muestra)
#perc_nulos_muestra

library(ggrepel)
ae_g_map <- ggplot(muestra, aes(x = ID_ESTADO, y = NULOS , label =  ESTRATO )) +
  geom_point(color="red", size = 2) +
  geom_text_repel(colour = "gray50") +
  labs(title = "NULOS por estado")
ae_g_map

norm_muestra_g <- ggplot(muestra, aes(sample=NULOS)) +
  geom_qq(distribution = stats::qnorm) +
  geom_qq_line(color = "red") +
  labs(title = "check if normal, muestra")


norm_total_g <- ggplot(computos, aes(sample=NULOS)) +
  geom_qq(distribution = stats::qnorm) +
  geom_qq_line(color = "red")+
  labs(title = "check if normal, computos")
norm_muestra_g + norm_total_g

hist_g <- ggplot(muestra, aes(x = NULOS)) + 
  geom_histogram() +
  labs(title = "Histograma NULOS")

hist_g


```
**Explicación**

Comparando los votos NULOS del total (~0.73%) con los de la muestra (~5.4%) se observa que hay un factor de 7.4 entre ambos valores. Eso implica que la muestra tiene mucho mas NULOS (en relación) que la población total. Revisando los números de NULOS por estado (1era grafica), se nota que algunos estados tienen un numero considerablemente más alta de votos NULOS que la mayoría. Si por alguna razón se tomó más muestras de estos estados, la análisis no puede ser exacta. En la mayoría de los estados hay muy pocos votos NULOS. Adicionalmente se analizó si la distribución de la $muestra$ y de $computos$ con respecto a sus votos NULOS son normales. Se ve claramente que la cola derecha de ambas es mucho más larga, lo que implica que es supuesto de una distribución normal es cuestionable.
