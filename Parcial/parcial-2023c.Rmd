---
title: "Parcial-2023"
output: html_document
---

**Entrega:** 10 de octubre antes de las 16:00 horas, por correo electrónico con 
el título fundamentos-parcial, un solo documento (pdf/html) por equipo.

**Instrucciones:**

* Tus respuestas deben ser claras y debes explicar 
los resultados, incluye también tus procedimientos/código de manera ordenada, 
y el código comentado.

* Se evaluará la presentación de resultados (calidad de las gráficas, tablas, 
...), revisa la sección de visualización en las notas.

* Se puede realizar individual o en parejas.

* Si tienes preguntas puedes escribirlas en el anuncio de canvas del examen.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, error=TRUE, message = TRUE)
library(tidyverse)
library(readr)
library(patchwork)
library(purrr)
library(nullabor)
```

## Pruebas de hipótesis

Nos solicitan hacer un análisis con el objetivo de probar un material nuevo para suela de zapatos (el material B) y ver si es comparable con el material que se usa normalmente (el material A).

Nos dan el siguiente conjunto de datos:

```{r}
zapatos <- read_csv("datos/zapatos-1.csv")
zapatos
```

1. Realiza una prueba de hipótesis visual y describe tus conclusiones (cuál es el
nivel de significancia de la prueba?).

```{r}
# reoganizar los datosy gruparlos material A (1) y B(2)

g_isnorm <- ggplot(zapatos, aes(sample= desgaste)) +
  geom_qq(distribution = stats::qnorm) +
  geom_qq_line(color = "red") +
 facet_wrap(zapatos$material)
g_isnorm

g_box <-  ggplot(zapatos, aes(y= desgaste, x = material)) +
  geom_boxplot()+
  geom_jitter(alpha = 1/3) +
  facet_wrap(zapatos$material)
g_isnorm + g_box

```


```{r}
# lineup de shoes

set.seed(123)
reps <- lineup(null_permute("material"), zapatos, n = 20)
reps

reps_mixed <- reps %>% 
  mutate(group_01 = factor(digest::digest2int("material") %% 177))
graph_quantile <- ggplot(reps_mixed, aes(y= desgaste, x = material)) +
  geom_boxplot() +
  geom_jitter(alpha = 1/3) +
  #geom_point()+
  #geom_tufteboxplot() +
  facet_wrap(reps_mixed$.sample)
graph_quantile
#decrypt("nsW7 Ykjk l3 gCPljlC3 Km") --> grafica 18
```


2. Realiza una prueba de permutaciones para la diferencia de las medias, escribe la hipótesis nula, la hipótesis alterna y tus conclusiones.

H0: El material B es comparable con el material A

Ha: El material B no es comparable con el material A

```{r}
set.seed(123)
materialA  <- zapatos %>% filter(material == 1)
materialB  <- zapatos %>% filter(material == 2)
material_tbl <- tibble(wear_materialA = materialA$desgaste, 
                       wear_materialB = materialB$desgaste)
diff_material <- material_tbl %>%  
  summarise(mean_wear_mat1 = mean(wear_materialA), 
            mean_wear_mat2 = mean(wear_materialB),
            diff_mat = mean_wear_mat2 - mean_wear_mat1)
 diff_material
 

# permutación
valores_ref <- lineup(null_permute("material"), zapatos, n = 10000) %>% 
  mutate(materia_as_chr = as.character(material)) %>% 
  group_by(.sample, material) %>% 
  summarise(wear = mean(desgaste)) %>% 
  pivot_wider(names_from = material, values_from = wear) %>%
  mutate(diff = `1` - `2`)
# decrypt("nsW7 Ykjk l3 gCPljlC3 44Tb")
g_valor_ref_q <- ggplot(valores_ref, aes(sample = diff)) +
  geom_qq(distribution = stats::qunif) +
  geom_hline(yintercept = diff_material$diff_mat, color = "red") 
g_valor_hist <- ggplot(valores_ref, aes(x = diff)) +
  geom_histogram(binwidth = 0.4) +
  coord_flip() +
  geom_vline(xintercept = diff_material$diff_mat, color = "red")
g_valor_ref_q + g_valor_hist


disp_perm <- ecdf(valores_ref$diff)
2 * min(disp_perm(diff_material$diff_mat), (1-disp_perm(diff_material$diff_mat)))
```
**Explicación**:
**Aunque se ve una diferencia en el desgaste del material A en comparación del matarial B se puede pensar que hay una diferencia. En base de los resultados se comprueba la hypothesis H0, no hay evidencias que el material B tiene un degsate diferente.**


3. Después de discutir con los responsables del proyecto descubrimos que nos 
faltaba conocer detalles del proceso generador de datos: el experimento se realizó asignando al azar un material a uno de sus zapatos y el otro material al otro zapato de cada niño.
¿Cómo incorporas esta información en tu prueba de hipótesis del inciso 2? ¿Cambian
tus conclusiones?

```{r}
zapatos <- read_csv("datos/zapatos-2.csv")
zapatos
```

```{r}
# visualisación 
set.seed(123)
zapatos <- read_csv("datos/zapatos-2.csv")
zapatos
g_desgaste_por_nino <-ggplot(zapatos, aes(y = desgaste)) +
  geom_point(aes(x = zapatos$material))+
  facet_wrap(~ niño) +
  xlab("material") + ylab("desgaste")

g_desgaste_por_nino

```

***Explicacicón***:
**En base de la analisis tomando en cuenta el usuario (niños) se nota que la diferencia notado anterioremente no está basada en el material (A=1, B=2) si ni e lo usuarios. Comparando el desgaste de los dos materiales, se ve que cada niño desgaste aprox de la misma manera los zapatos. La diferencia en los desgaste están mas bien un resultado del usuario.**


```{r}
zapatos_tbl <- zapatos %>% group_by(niño) %>% 
  pivot_wider(names_from = niño, values_from = desgaste) 

zapatos_tbl %>% 
  bind_rows(diff = zapatos_tbl[1,] - zapatos_tbl[2,])
#diff_material_per_child <- zapatos_tbl[3,2:11]
# se tomo los valores de la diferencia de desgaste de por niños via "copy and paste" para hacer el nuevo dada frame y analizarlo (dmpc = difference of material per child).
dmpc_tbl <- tibble(dmpc = c(-0.800, -0.600, -0.300,  0.100, -1.10, 0.200, -0.300,  -0.5,  -0.5, -0.300))


calc_diferencia_2 <- function(data){
  data %>% 
    group_by(dmpc) %>% 
    summarise(wear = mean(dmpc), .group = 'drop') %>% 
    pull(wear)
}
mean_org <- mean(calc_diferencia_2(dmpc_tbl))
set.seed(123)
reps <- lineup(null_permute("dmpc"), dmpc_tbl, n = 10000)
# decrypt("nsW7 Ykjk l3 gCPljlC3 FFbb")
valores_ref2 <- reps %>% 
  group_by(.sample) %>% 
  nest() %>% 
  mutate(diff = lapply(data, calc_diferencia_2)) %>% 
  unnest(diff)

valores_ref2

g_valor_ref2_q <- ggplot(valores_ref2, aes(sample = diff)) +
  geom_qq(distribution = stats::qnorm) +
  geom_hline(yintercept = mean_org, color = "red") 
 

g_valor_ref2_hist <- ggplot(valores_ref2, aes(y = diff)) +
  geom_histogram() +
  geom_hline(yintercept = mean_org, color = "red") 
g_valor_ref2_q +  g_valor_ref2_hist
```

***Explicación***
**Estas graficas confirman que no hay evidencias para rechazar la hipotesis nula (H0)**

## Bootstrap

#### Antecedentes 

En México, las elecciones tienen lugar un domingo, los resultados oficiales 
del proceso se presentan a la población una semana después. A fin de evitar 
proclamaciones de victoria injustificadas durante ese periodo el INE organiza un 
conteo rápido. Un conteo rápido es un procedimiento para estimar, a partir de una muestra 
aleatoria de casillas, el porcentaje de votos a favor de cada opción en la boleta. 

En 2021 se realizó un conteo rápido para estimar los resultados de la [consulta popular 2021](https://ine.mx/conteo-rapido-consulta-popular-2021/) y en los siguientes
incisos estimarán los resultados de la consulta y evaluarán la metodología. 

##### Diseño de la muestra

El diseño utilizado en los conteos rápidos es *muestreo estratificado simple*, 
es decir:

i) se particionan las casillas de la pablación en estratos (cada casilla
pertenece a exactamente un estrato), y 

ii) dentro de cada estrato se usa *muestreo aleatorio* para seleccionar las 
casillas que estarán en la muestra. 

##### Estimación 

Una de las metodolgías de estimación, que se usa en el conteo rápido (tanto de 
elecciones como en consultas) es *estimador de razón combinado*, con
intervalos de 95% de confianza construidos con el método normal y error 
estándar bootstrap. En este ejercicio debes construir intervalos usando este 
procedimiento.

Para cada opción en la consulta (sí/no/nulos) usarás la muestra del conteo rápido
para estimar los resultados de la consulta.

1. Calcula el estimador de razón combinado, para muestreo estratificado la 
fórmula es:

$$\hat{p}=\frac{\sum_h \frac{N_h}{n_h} \sum_i Y_{hi}}{\sum_h \frac{N_h}{n_h} \sum_i X_{hi}}$$
  donde:

  * $\hat{p}$ es la estimación de la proporción de votos que recibió la opción (ej: *sí*).

  * $Y_{hi}$ es el número total de votos que recibió *la opción* (ej: *sí*)
en la $i$-ésima casillas, que pertence al $h$-ésimo estrato.

  * $X_{hi}$ es el número total de votos en la $i$-ésima casilla, que pertence al 
$h$-ésimo estrato. 

  * $N_h$ es el número total de casillas en el $h$-ésimo estrato.

  * $n_h$ es el número de casillas del $h$-ésimo estrato que se seleccionaron en 
la muestra.


##### Datos 

Necesitarás los siguientes datos:

* Cómputos [aquí](https://computos.cp2021.ine.mx/votos-distrito/mapa)

* Muestra del conteo rápido usada en la estimación [aquí](https://ine.mx/conteo-rapido-consulta-popular-2021/)

```{r}
# preprocesamiento de tablas de datos
computos <- read_delim("datos/20210802-2130_INE-CONSULTA-POPULAR-2021/20210802-2130_COMPUTOS-INE-CP2021.csv", 
    delim = "|", escape_double = FALSE, trim_ws = TRUE, quote = "\'",
    skip = 5)
computos <- computos |> 
  rename(ID = CLAVE_MRCP) |> 
  mutate(ESTRATO = str_c(str_pad(ID_ENTIDAD, 2, pad = "0"), 
                         str_pad(ID_DISTRITO_FEDERAL, 2, pad = "0")),
         LISTA_NOMINAL = LISTA_NOMINAL_MRCP, 
         TOTAL = TOTAL_OPINIONES)

computos_tidy <- computos |> group_by(ESTRATO) |> 
  mutate(N = n()) |> 
  ungroup()


muestra <- read_delim("https://ine.mx/wp-content/uploads/2021/08/Conteos-ConsPop21-Lista-MuestraCalculo.txt", delim = "|", skip = 1) 
muestra_tidy <- muestra |> 
  mutate(
    ID_ESTADO = str_pad(ID_ESTADO, 2, pad = "0"),
    SECCION = str_pad(SECCION, 4, pad = "0"),
    ID_CASILLA = str_pad(ID_CASILLA, 2, pad = "0"),
    ID = str_c(ID_ESTADO, SECCION, TIPO_CASILLA, ID_CASILLA)
    ) |> 
  group_by(ESTRATO) |> 
  mutate(n = n()) |> 
  ungroup()
```


```{r}

#Estimador si 
estim_p__gorro_si <- function(sample2Eval, pop_total){
  y_hi_si <- sample2Eval %>%
    group_by(ESTRATO) %>%
    summarise(count_yes = sum(sample2Eval$SI)) 

  x_hi <- sample2Eval %>%
    ungroup() %>%
    group_by(ID_CASILLA, ESTRATO) %>%
    summarise(count_votos = sum(TOTAL), .groups = 'drop')

  N_h <- pop_total %>%
    group_by(ESTRATO) %>%
    summarise(count_casilla = n_distinct(pop_total$ID_MRCP))

  n_h <- muestra_tidy %>%
    group_by(ESTRATO) %>%
    summarise(count_casilla = n_distinct(muestra_tidy$ID_CASILLA))

  proportion <- inner_join(N_h, n_h, by = "ESTRATO") %>%
    mutate(division = count_casilla.x / count_casilla.y)

  a_si <- inner_join(proportion, y_hi_si, by = "ESTRATO") %>%
    mutate(mult = division * count_yes)

    b <- inner_join(proportion, x_hi, by="ESTRATO") %>%
      mutate(mult = division * count_votos)

  p_gorro_si <- sum(a_si$mult) / sum(b$mult)

}

p_gorro_si <- estim_p__gorro_si(muestra_tidy, computos)
  
```

```{r}
#Estimador no
estim_p__gorro_no <- function(sample2Eval, pop_total){
  y_hi_no <- sample2Eval %>%
    group_by(ESTRATO) %>%
    summarise(count_no = sum(sample2Eval$NO)) 

  x_hi <- sample2Eval %>%
    ungroup() %>%
    group_by(ID_CASILLA, ESTRATO) %>%
    summarise(count_votos = sum(TOTAL), .groups = 'drop')

  N_h <- pop_total %>%
    group_by(ESTRATO) %>%
    summarise(count_casilla = n_distinct(pop_total$ID_MRCP))

  n_h <- sample2Eval %>%
    group_by(ESTRATO) %>%
    summarise(count_casilla = n_distinct(sample2Eval$ID_CASILLA))

  proportion <- inner_join(N_h, n_h, by = "ESTRATO") %>%
    mutate(division = count_casilla.x / count_casilla.y)

  a_no <- inner_join(proportion, y_hi_no, by = "ESTRATO") %>%
    mutate(mult = division * count_no)
  
  b <- inner_join(proportion, x_hi, by="ESTRATO") %>%
    mutate(mult = division * count_votos)

  p_gorro_no <- sum(a_no$mult) / sum(b$mult)
}
p_gorro_no <- estim_p__gorro_no(muestra_tidy, computos)
##TODO SE SACA DE LA MUESTRA EXCEPTO N_H pero lo resto si

#no sé como sacar p gorro
##por qué me salen 11 y 10 
```

```{r}

#Estimador nulos
estim_p__gorro_nulos<- function(sample2Eval, pop_total){
  
  y_hi_nulos <- sample2Eval %>%
    group_by(ESTRATO) %>%
    summarise(count_nulos = sum(sample2Eval$NULOS)) 

  x_hi <- sample2Eval %>%
    ungroup() %>%
    group_by(ID_CASILLA, ESTRATO) %>%
    summarise(count_votos = sum(TOTAL), .groups = 'drop')

  N_h <- pop_total %>%
    group_by(ESTRATO) %>%
    summarise(count_casilla = n_distinct(pop_total$ID_MRCP))

  n_h <- sample2Eval %>%
    group_by(ESTRATO) %>%
    summarise(count_casilla = n_distinct(sample2Eval$ID_CASILLA))


  proportion <- inner_join(N_h, n_h, by = "ESTRATO") %>%
    mutate(division = count_casilla.x / count_casilla.y)

  a_nulos <- inner_join(proportion, y_hi_nulos, by = "ESTRATO") %>%
    mutate(mult = division * count_nulos)

  b <- inner_join(proportion, x_hi, by="ESTRATO") %>%
    mutate(mult = division * count_votos)

  p_gorro_nulos <- sum(a_nulos$mult) / sum(b$mult)
}
 p_gorro_nulos <-estim_p__gorro_nulos(muestra_tidy, computos)
 
total <- p_gorro_no + p_gorro_nulos + p_gorro_si

percentage_p_si <- p_gorro_si / total
percentage_p_no <- p_gorro_no / total
percentage_p_nulos <- p_gorro_nulos / total
##TODO SE SACA DE LA MUESTRA EXCEPTO N_H pero lo resto si

#no sé como sacar p gorro
##por qué me salen 11 y 10 
```



2. Utiliza **bootstrap** para calcular el error estándar, y reporta tu 
estimación del error.
    + Genera 1000 muestras bootstrap.
    + Recuerda que las muestras bootstrap tienen que tomar en cuenta la 
    metodología que se utilizó en la selección de la muestra original, en este
    caso implica que para cada remuestra debes tomar muestra aleatoria independiente
    dentro de cada estrato.
```{r}
set.seed(1234)
esti_all <- function(sample2Eval, pop_total){
  p_gorro_si <-estim_p__gorro_si(sample2Eval,  pop_total)
  p_gorro_no <-estim_p__gorro_no(sample2Eval,  pop_total)
  p_gorro_nulos <-estim_p__gorro_nulos(sample2Eval,  pop_total)

 
  total <- p_gorro_no + p_gorro_nulos + p_gorro_si

  percentage_p_si <- p_gorro_si / total
  percentage_p_no <- p_gorro_no / total
  percentage_p_nulos <- p_gorro_nulos / total
  perc_total <- c(percentage_p_si, percentage_p_no, percentage_p_nulos)
}
  
get_sample <- function(sample2eval){
  resample <- slice_sample(sample2eval %>% group_by(ESTRATO), prop = 1, replace = TRUE)
}
# calucalndo 1000 bootstraps
boot_sample <- map(1:1000,~ esti_all(get_sample(muestra_tidy), computos))
# resultado: separar los valores en arrarys para aplicar sd()
# inicial:
p_hat_si_vec <- c(boot_sample[[1]][1])  
p_hat_no_vec <- c(boot_sample[[1]][2])  
p_hat_nu_vec <- c(boot_sample[[1]][3])  
# adjuntar los demas valors
for(idx in 2:1000){
  p_hat_si_vec <- c(p_hat_si_vec, boot_sample[[idx]][1])  
  p_hat_no_vec <- c(p_hat_no_vec, boot_sample[[idx]][2])  
  p_hat_nu_vec <- c(p_hat_nu_vec, boot_sample[[idx]][3])  
}
# data frame p_hat
p_hat_tbl <- tibble(p_hat_si = p_hat_si_vec, 
                p_hat_no = p_hat_no_vec,
                p_hat_nu = p_hat_nu_vec)

# calular el error estandard
ee_p_hat_si <- sd(p_hat_si_vec)
ee_p_hat_no <- sd(p_hat_no_vec)
ee_p_hat_nu <- sd(p_hat_nu_vec)
ee_res_boot <- tibble(ee_p_hat_si, ee_p_hat_no, ee_p_hat_nu)
ee_res_boot
g_si <- ggplot(p_hat_tbl, aes(p_hat_si)) + 
  geom_histogram() +
  geom_vline(xintercept = mean(p_hat_tbl$p_hat_si), colour = "red")
g_no <- ggplot(p_hat_tbl, aes(p_hat_no)) + 
  geom_histogram() +
  geom_vline(xintercept = mean(p_hat_tbl$p_hat_no), colour = "red")
g_nu <- ggplot(p_hat_tbl, aes(p_hat_nu)) + 
  geom_histogram() +
  geom_vline(xintercept = mean(p_hat_tbl$p_hat_nu), colour = "red")

#g_si + g_no + g_nu
```

3. Construye un intervalo del 95% de confianza utilizando el método normal. Revisa 
si el supuesto de normalidad es razonable.

```{r}
# intervalos de confianza p_hat_si
interv_p_hat_si_95 <- c(percentage_p_si - 2*ee_p_hat_si, percentage_p_si + 2*ee_p_hat_si)
interv_p_hat_si_95
#el supuesto de normalidad es razonable?
g_si_qq <- ggplot(p_hat_tbl, aes(sample = p_hat_si)) +
  geom_qq(distribution  = stats::qnorm) +
  geom_qq_line(color = "red") +
  geom_hline(yintercept = interv_p_hat_si_95[1], colour="green")+
  geom_hline(yintercept = interv_p_hat_si_95[2], colour="green")
g_si + g_si_qq
# intervalos de confianza p_hat_no
interv_p_hat_no_95 <- c(percentage_p_no - 2*ee_p_hat_no, percentage_p_no + 2*ee_p_hat_no)
interv_p_hat_no_95
#el supuesto de normalidad es razonable?
g_no_qq <- ggplot(p_hat_tbl, aes(sample = p_hat_no)) +
  geom_qq(distribution  = stats::qnorm) +
  geom_qq_line(color = "red") +
  geom_hline(yintercept = interv_p_hat_no_95[1], colour="green")+
  geom_hline(yintercept = interv_p_hat_no_95[2], colour="green")
g_no + g_no_qq

# intervalos de confianza p_hat_nu
interv_p_hat_nu_95 <- c(percentage_p_nulos - 2*ee_p_hat_nu, percentage_p_nulos + 2*ee_p_hat_nu)
interv_p_hat_nu_95 
#el supuesto de normalidad es razonable?
g_nu_qq <- ggplot(p_hat_tbl, aes(sample = p_hat_nu)) +
  geom_qq(distribution  = stats::qnorm) +
  geom_qq_line(color = "red") +
  geom_hline(yintercept = interv_p_hat_nu_95[1], colour="green")+
  geom_hline(yintercept = interv_p_hat_nu_95[2], colour="green")
g_nu + g_nu_qq

```
**Explicación**:


4. Reporta tus intervalos en una tabla. Compara la longitud de los 3 intervalos y 
describe que observas.

```{r}
#crear una tabla con los intervalos

tabla_intervalos <- tibble(p = c("p_hat_si", "p_hat_no","p_hat_nulos"),
                            low = c(interv_p_hat_si_95[1], interv_p_hat_no_95[1], interv_p_hat_nu_95[1]), 
                            up = c(interv_p_hat_si_95[2], interv_p_hat_no_95[2], interv_p_hat_nu_95[2]), 
                            int_len =c(interv_p_hat_si_95[2] - interv_p_hat_si_95[1],
                                       interv_p_hat_no_95[2] - interv_p_hat_no_95[1],
                                       interv_p_hat_nu_95[2] - interv_p_hat_nu_95[1]) )
tabla_intervalos
```


3. ¿Tus intervalos contienen los valores observados en los cómputos? Explica los
resultados observados.

```{r}
p_si_total <- sum(computos$OPINION_SI)/sum(computos$TOTAL)
print("¿el valor final de SI está dentro del intervalo estimado?")
(p_si_total>interv_p_hat_si_95[1] & p_si_total<interv_p_hat_si_95[2])
p_no_total <- sum(computos$OPINION_NO)/sum(computos$TOTAL)
print("¿el valor final de NO está dentro del intervalo estimado?")
(p_no_total>interv_p_hat_no_95[1] & p_no_total<interv_p_hat_no_95[2])
p_nu_total <- sum(computos$NULOS)/sum(computos$TOTAL)
print("¿el valor final de NULO está dentro del intervalo estimado?")
(p_nu_total>interv_p_hat_nu_95[1] & p_nu_total<interv_p_hat_nu_95[2])

```


#### Calibración

Selecciona al menos 50 muestras del mismo tamaño y con el mismo diseño que la 
muestra utilizada en el conteo rápido. Esto es, selecciona el 
mismo número de casillas, usando muestreo aleatorio simple dentro de cada estrato.

```{r}
# seleción de 50 muestras
muestra_new <- computos_tidy %>% slice_sample(n=1745, replace = TRUE) 


```


* Para cada muestra calcula un intervalo del 95% de confianza usando bootstrap.

```{r}
# este estimador hace lo mismo que estimador_p(), la diferencia es el tio de sample2eval, es la muestra de computos_tidy, se ajustaron algunas variable: ID en lugar de ID_CASILLA, OPINION_NO en lugar de NO y OPINION_SI en lugar de SI
estimador_p_comp <- function(sample2eval, pop_total){
  
  Y_hi <- sample2eval %>% 
    group_by(ESTRATO, ID) %>% 
    summarise(votos_si = sum(OPINION_SI), votos_no = sum(OPINION_NO),votos_nu = sum(NULOS))

  X_hi <- sample2eval %>% 
    group_by(ESTRATO, ID) %>% 
    summarise(votos_TOTAL = sum(TOTAL))

  N <- pop_total %>%  
    group_by(ESTRATO) %>% 
    summarise(N = sum(N))
  n <- sample2eval %>% 
    group_by(ESTRATO) %>% 
    summarise(n = sum(N))

  den_tot <- sum(N$N/n$n *sum(X_hi$votos_TOTAL))
  p_hat_si <- sum(N$N/n$n *sum(Y_hi$votos_si))/(den_tot)
  p_hat_no <- sum(N$N/n$n *sum(Y_hi$votos_no))/(den_tot)
  p_hat_nu <- sum(N$N/n$n *sum(Y_hi$votos_nu))/(den_tot)
  perc_sample <- tibble(p_hat_si, p_hat_no, p_hat_nu, 
                        check = p_hat_si + p_hat_no + p_hat_nu)
}

#est_muestra_new <- estimador_p_comp(muestra_new, computos_tidy)

set.seed(389)
sim_interval <- function(rep, size = 1745, id = "si"){
  muestra_cr <- slice_sample(computos_tidy, n=size)
  total_est_tbl <- estimador_p_comp (muestra_cr, computos_tidy)
  if(id == "si"){
    total_est <- total_est_tbl$p_hat_si
  }
  if(id == "no"){
    total_est <- total_est_tbl$p_hat_no
  }
  if(id == "nu"){
    total_est <- total_est_tbl$p_hat_nu
  }
  # define el estimador
  calc_estimador <- function(data){
    p_hat<-estimador_p_comp(data, computos_tidy)
    if(id == "si"){
      p_hat_out <- p_hat$p_hat_si
    }
    if(id == "no"){
      p_hat_out <- p_hat$p_hat_no
    }
    if(id == "nu"){
      p_hat_out <- p_hat$p_hat_nu
    }
    class(p_hat_out)
    p_hat_out
  }
  # define el proceso de remuestra
  muestra_boot <- function(data){
    slice_sample(data, prop = 1, replace = TRUE)
  }

 totales_boot <-  map_dbl(1:1000, ~ calc_estimador(muestra_boot(muestra_cr))) %>% 
    tibble(total_boot = .) %>% 
    summarise(ee_boot = sd(total_boot)) %>% 
    mutate(inf = total_est - 2*ee_boot, sup = total_est + 2*ee_boot) %>% 
    mutate(rep = rep)
  totales_boot
}
#sim_intervalo_si <- map(1:50, ~sim_interval(.x, size = 1745, id = "si"))
#write_rds(sim_intervalo_si, "cache/sim_intervalo_si.rds")

sim_intervalo_si <- read_rds("cache/sim_intervalo_si.rds")
#sim_intervalo_nu <- map(1:50, ~sim_interval(.x, size = 1745, id = "nu"))
#write_rds(sim_intervalo_nu, "cache/sim_intervalo_nu.rds")
sim_intervalo_no <- read_rds("cache/sim_intervalo_no.rds")
#sim_intervalo_no <- map(1:50, ~sim_interval(.x, size = 1745, id = "no"))
#write_rds(sim_intervalo_no, "cache/sim_intervalo_no.rds")
sim_intervalo_nu <- read_rds("cache/sim_intervalo_nu.rds")

```


* Grafica los intervalos y calcula la proporción de ellos que contienen el 
verdadero valor observado. Describe tus observaciones y compara con el intervalo 
obtenido en el ejercicio anterior.

```{r}
# graficas para calibaracion SI
P_expected <- p_si_total
sim_intervalo_si_tbl <- sim_intervalo_si |> 
    bind_rows() |>
            mutate(cubre = inf < P_expected & P_expected < sup) 
intervalo_si_plot <-  ggplot(sim_intervalo_si_tbl, aes(x = rep)) +
      geom_hline(yintercept = P_expected, colour = "red") +
      geom_linerange(aes(ymin = inf, ymax = sup, colour = cubre)) +
  labs(title = "calibaración SI") +
  ylab("invervalls")

# graficas para calibaración NO    
P_expected <- p_no_total
sim_intervalo_no_tbl <- sim_intervalo_no |> 
    bind_rows() |>
            mutate(cubre = inf < P_expected & P_expected < sup) 
intervalo_no_plot <-  ggplot(sim_intervalo_no_tbl, aes(x = rep)) +
      geom_hline(yintercept = P_expected, colour = "red") +
      geom_linerange(aes(ymin = inf, ymax = sup, colour = cubre)) +
  labs(title = "calibaración NO") +
  labs(title = "calibaración NO") +
  ylab("invervalls")

 
# graficas para calibaración NULOS   
P_expected <- p_nu_total
sim_intervalo_nu_tbl <- sim_intervalo_nu |> 
    bind_rows() |>
            mutate(cubre = inf < P_expected & P_expected < sup) 
intervalo_nu_plot <-  ggplot(sim_intervalo_nu_tbl, aes(x = rep)) +
  geom_hline(yintercept = P_expected, colour = "red") +
  geom_linerange(aes(ymin = inf, ymax = sup, colour = cubre))+
  labs(title = "calibaración NULOS") +
  ylab("invervalls")


intervalo_si_plot 
intervalo_no_plot 
intervalo_nu_plot
```


#### Análisis Exploratorio

Un voto nulo corresponde a una boleta donde el ciudadano acudió a las urnas
y anuló su voto. 

Antes de contestar los siguiente incisos piensen que rango esperarían ver para la
proporción de votos nulos en una casilla.

* Describe la distribución de datos nulos en la muestra, y como se relaciona con 
el total de votos, realiza gráficas y describe tus observaciones.

* En la distribución de proporción de nulos se observan datos atípicos, ¿cuál 
crees que sea la razón de estas observaciones extremas? ¿consideras que se
deben eliminar de la muestra antes de realizar la estimación?

```{r}
votos_total <- sum(computos$TOTAL_OPINIONES)
votos_nulos_total <- sum(computos$NULOS)
votos_total_muestra <- sum(muestra$TOTAL)
votos_nulos_muestra <- sum(muestra$NULOS)

perc_nulos_total <- votos_nulos_total/votos_total
perc_nulos_total
perc_nulos_muestra <- votos_nulos_muestra/votos_total_muestra
perc_nulos_muestra

library(ggrepel)
ae_g_map <- ggplot(muestra, aes(x = ID_ESTADO, y = NULOS , label =  ESTRATO )) +
  geom_point(color="red", size = 2) +
  geom_text_repel(colour = "gray50")
ae_g_map

norm_muestra_g <- ggplot(muestra, aes(sample=NULOS)) +
  geom_qq(distribution = stats::qnorm) +
  geom_qq_line(color = "red")
norm_muestra_g

norm_total_g <- ggplot(computos, aes(sample=NULOS)) +
  geom_qq(distribution = stats::qnorm) +
  geom_qq_line(color = "red")
norm_total_g
hist_g <- ggplot(muestra, aes(x = NULOS)) + 
  geom_histogram()

hist_g

```


