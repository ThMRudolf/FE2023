---
title: "tarea_09, Thomas M. Rudolf"
output: html_document
date: "2023-10-13"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(patchwork)
```

#### Ejercicio 1: crear funcion de verosim con el ejemplo de numéro de errores

```{r}
crear_log_verosim <- function(n=500, n_err){
  # n es tamaño de muestra 
  # n_err el número de errores detectados (datos)
  n_corr <- n - n_err
  log_verosim <- function(p){
    n_err * log(p) + n_corr * log(1-p)
  }
}
```

## Pregunta: ¿qué devuelve esta función?

La funcíon regresa la probabilidad de un evento (en logaritmo
naturalis - ln). \###################### \## Utiliza esta función para
construir la función \## de log verosimilitud cuando los datos
observados \## son n = 500, y le número de errores observados es 121

## aquí tu codigo

```{r}
n <- 500
n_err <- 121
p = 121/500
log_vero <- crear_log_verosim(500, 121)
```

## Pregunta: ¿de qué parámetros depende esta ultima función?

La función **log_verosim** es una funcion "simbolico" (así se llamaria
en Matlab) de la función **crear_log_verosim**. El parametar que hay que
definir es la probabilidad p y se varía enter 0 y 1 en deltas de 0.001.
\## ¿Dónde quedaron los datos observados? En la funciòn
**crear_log_verosim**. \####################### \# Usa max verosimilitud
para estimar el porcentaje de errores \# en la tabla de datos de donde
se sacó la muestra \# usa la función optimize

# rellena

```{r}
sol <- optimize(log_vero, c(0, 1), maximum = TRUE)
sol$maximum
```

######################## 

# grafica la funcion de verosimilitud para p entre cero y uno

```{r}
grafica_tbl <- tibble(p = seq(0, 1, 0.001)) %>% 
  mutate(prob = log_vero(p) )
  
g1<-ggplot(grafica_tbl, aes(x = p, y = prob)) +
  geom_line() + 
  geom_vline(xintercept = sol$maximum, color="red")
g1
```

############################# 

# Repite el ejercicio anterior si observas 317 errores

```{r}
log_vero <- crear_log_verosim(500, 317)
sol2 <- optimize(log_vero, c(0, 1), maximum = TRUE)
sol2$maximum

grafica_tbl2 <- tibble(p = seq(0, 1, 0.001)) %>% 
  mutate(prob = log_vero(p) )
  
g2<-ggplot(grafica_tbl2, aes(x = p, y = prob)) +
  geom_line() + 
  geom_vline(xintercept = sol2$maximum, color="red")
g2
```

#### Ejercicio 2: normal

## Estimación de parámetros de una distribución normal

# 1. Considera una muestra de variables aleatorias Gaussianas

# Escribe la verosimilitud para una muestra de tamaño n y después escribe la

# función de log-verosimilitud.

Verosimilitud para un xi:

$$
u_i = \frac{(x_i - \mu)}{2\sigma}$$
$$
\mathcal{L}_n(x_i) = \frac{1}{\sigma \sqrt{2\pi}}\exp{u^2}
$$
verosimilotud de $n$ $x_i$
$$
\mathcal{L}_n(\theta) = \prod_{i=1} \mathcal{L}_n(x_i) = \prod_{i=1} \frac{1}{\sigma \sqrt{2\pi}}\exp{u_1^2} =\prod_{i=1} \frac{1}{\sigma \sqrt{2\pi}}\exp{\frac{(x_i - \mu)}{2\sigma}^2}
$$
2. Generamos una mu y una sigma al azar para que

## no sepamos cuáles son

#fijamos semilla
```{r}
set.seed(1234)
m <- runif(1, 5, 10) # media entre 5 y 10
desv_est <- runif(1, 0, 2) # desviación estándar entre 0 y 2
```

#simulamos una muestra con la que trabajaremos.

```{r}
set.seed(123)
x <- rnorm(150, mean = m, sd = desv_est)
#log_verosim <- create_log_Gauss_Distribution(m , desv_est)
```

######################################### 

## 2. Checa tus datos usando un histograma

```{r}
gauss_tibble <- tibble(y = x)
ggplot(gauss_tibble, aes(x = y)) + 
  geom_histogram()
```

## Primero estima a ojo por dónde creen que esté

## la media y la desviación estándar

La desviacion estandard debe estar como aprox 1.3 (8/6) y el promedio
aprox. 5.

########################### 

## 3. Estima la media y la desviación estándar usando estimador plug-in

```{r}
get_sample <- function(sample2eval){
  new_sample <- slice_sample(sample2eval, prop = 1, replace = TRUE)
  return(new_sample)
}
calc_estim <- function(data2estim, type = "mean"){
  estim_res <- data2estim %>% 
    summarise(mean_gauss = mean(y), sd_gauss = sd(y))
  
  if(type == "mean"){
    return(estim_res$mean_gauss)
  }
  if(type == "sd"){
    return(estim_res$sd_gauss)
  }
}
media_est <- tibble(mean_estim = map_dbl(1:100, ~calc_estim(get_sample(gauss_tibble), "mean"))) 
media_est <- mean(media_est$mean_estim)
  de_est <- tibble(sd_estim = map_dbl(1:100, ~calc_estim(get_sample(gauss_tibble), "sd"))) 
  de_est <- mean(de_est$sd_estim)
gauss_tibble <- gauss_tibble %>% mutate(mean_estim = media_est, sd_estim = de_est)
gauss_tibble
```

############### 

## 4. Escribe una función que regrese la función de verosimilitud dado una muestra (revisa las notas en la sección de más de un parámetro)

```{r}
create_log_Gauss_Distribution <- function(x){
  # f(x)= 1/(sig*sqrt(2*pi))*exp(-0.5*((xi-mu)/sig)^2)
  # log(1) = 0
  # log(x/y) = log(x) - log(y)
  # log(x*y) = log(x) + log(y)
  
  log_p <-function(pars){
    mu = pars[1]
    sig = pars[2]
    v <- sig*sqrt(2*pi)
    u <- (x-mu)/sig
    fx <- 1/(v)*exp(-0.5*(u)^2)
    # usando log
    log_fx <- (0 - log(v) - 0.5*u^2)
    log_fx
  }
  log_p
}

crear_log_p <- function(x){
  log_p <- function(pars){
    media = pars[1]
    desv_est = pars[2]
    # ve la ecuación del ejercicio anterior
    z <- (x - media) / desv_est
    log_verosim <- -(log(desv_est) + 0.5 * mean(z ^ 2))
    log_verosim
  }  
  log_p
}
log_p <- crear_log_p#create_log_Gauss_Distribution(x)
```

## 5. Usa la función del paso anterior para crear una función de verosimilitud que dependerá de mu y sigma

## 6.Optimiza y compara tus estimaciones con las del paso 3

```{r}
res <- optim(c(0, 0.5), log_p, control = list(fnscale = -1, maxit = 1000), method = "Nelder-Mead")
res$convergence
#
est_mv <- tibble(parametro = c("mu", "sigma"), estimador = res$par) %>% 
  column_to_rownames(var = "parameter")
est_mv
```
